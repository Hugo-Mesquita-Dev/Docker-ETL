
# ğŸš€ Projeto Docker-ETL: Pipeline de Dados com Spark, Airflow e Grafana

Este projeto implementa um pipeline de dados completo usando:

- âš™ï¸ **Spark** para processamento ETL
- ğŸ¯ **Airflow** para orquestraÃ§Ã£o
- ğŸ—„ï¸ **PostgreSQL** como banco de dados
- ğŸ“Š **Grafana** e **Metabase** para visualizaÃ§Ã£o
- ğŸ“ˆ **Prometheus** para monitoramento

Tudo containerizado com **Docker** para fÃ¡cil reproduÃ§Ã£o e escalabilidade.

---

## ğŸ“‹ PrÃ©-requisitos

- Docker Engine **20+**
- Docker Compose **2.10+**
- **4GB+** de RAM disponÃ­vel

---

## ğŸš€ InstalaÃ§Ã£o

Clone o repositÃ³rio:

```bash
git clone [URL_DO_SEU_REPO]
cd Docker-ETL
```

Inicie os containers:

```bash
docker-compose up -d --build
```

Acesse as ferramentas:

- **Airflow:** [http://localhost:8080](http://localhost:8080) â€” *Login:* `admin` / *Senha:* `admin`
- **Grafana:** [http://localhost:3001](http://localhost:3001) â€” *Login:* `admin` / *Senha:* `admin`
- **Metabase:** [http://localhost:3000](http://localhost:3000) â€” *(configurar no primeiro acesso)*
- **Prometheus:** [http://localhost:9090](http://localhost:9090)

---

## ğŸ› ï¸ Estrutura do Projeto

```
Docker-ETL/
â”œâ”€â”€ data/               # Dados de entrada/saÃ­da
â”‚   â”œâ”€â”€ input/          # CSVs/JSONs de origem
â”‚   â””â”€â”€ output/         # Dados processados (Parquet)
â”œâ”€â”€ airflow/            # DAGs e configuraÃ§Ãµes
â”œâ”€â”€ grafana/            # Dashboards e datasources
â”œâ”€â”€ scripts/            # CÃ³digos Spark
â”œâ”€â”€ docker-compose.yml  # OrquestraÃ§Ã£o dos serviÃ§os
â””â”€â”€ Dockerfile          # Imagem customizada do Spark
```

---

## ğŸ”„ Fluxo de Dados

- **ExtraÃ§Ã£o:**
  - Spark lÃª os arquivos `data/input/vendas_2023.csv` e `produtos.json`.

- **TransformaÃ§Ã£o:**
  - Limpeza, joins e agregaÃ§Ãµes realizadas (ver arquivo `scripts/etl_spark.py`).

- **Carga:**
  - Grava os dados em:
    - Banco **PostgreSQL** (tabela `vendas`)
    - Arquivos **Parquet** em `data/output/`

- **VisualizaÃ§Ã£o:**
  - Dashboards no **Grafana** e **Metabase**.

---

## âš™ï¸ ConfiguraÃ§Ã£o AvanÃ§ada

### ğŸ”§ VariÃ¡veis de Ambiente

Edite o arquivo `docker-compose.yml` para ajustar:

```yaml
environment:
  POSTGRES_PASSWORD: senha123       # ğŸ”’ Altere para produÃ§Ã£o!
  AIRFLOW__CORE__FERNET_KEY: sua_chave_aqui
```

### â• Adicionar Novas DAGs

Coloque seus workflows no diretÃ³rio:

```
airflow/dags/
```

### ğŸ“ˆ Monitoramento Customizado

Edite o arquivo `prometheus.yml` para adicionar novas mÃ©tricas ou targets.

---

## ğŸ›‘ Comandos Ãšteis

| FunÃ§Ã£o               | Comando                                        |
|----------------------|------------------------------------------------|
| Reiniciar serviÃ§os   | `docker-compose restart`                      |
| Ver logs             | `docker-compose logs -f [serviÃ§o]`            |
| Parar tudo           | `docker-compose down`                         |
| Limpar dados         | `docker-compose down -v`                      |

---

## ğŸ“Š Dashboards Recomendados

### ğŸ”¹ **Grafana**

- **Spark:** ID `10258`
- **PostgreSQL:** ID `9628`

### ğŸ”¸ **Metabase**

Crie questÃµes SQL como:

```sql
SELECT * 
FROM vendas 
WHERE data > NOW() - INTERVAL '7 days';
```

---

## â‰ï¸ SoluÃ§Ã£o de Problemas

### âš ï¸ Erro no Spark

```bash
docker-compose exec spark-etl tail -n 50 /opt/spark/logs/spark.log
```

### âš ï¸ Airflow nÃ£o inicia

```bash
docker-compose exec airflow airflow db check
```

### âš ï¸ Grafana sem dados

Verifique se o datasource **Prometheus** estÃ¡ configurado corretamente:

```
URL: http://prometheus:9090
```

---

## ğŸ“„ LicenÃ§a

ğŸ“ MIT License â€” Use livremente para projetos pessoais e comerciais.

ContribuiÃ§Ãµes sÃ£o bem-vindas!  
ğŸ‘‰ Envie PRs ou abra issues no GitHub.

---

## ğŸ”— Links Ãšteis

- [DocumentaÃ§Ã£o Spark](https://spark.apache.org/docs/latest/)
- [Guia Airflow](https://airflow.apache.org/docs/)

---

**Happy Coding! ğŸš€**
